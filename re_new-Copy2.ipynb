{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time, datetime\n",
    "from pprint import pprint\n",
    "\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.models import CoherenceModel\n",
    " \n",
    "import spacy\n",
    " \n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim # don't skip this\n",
    "\n",
    "from eunjeon import Mecab\n",
    "    \n",
    "    \n",
    "    \n",
    "# Enable logging for gensim - optional\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
    " \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train_detoken.csv\")\n",
    "train.drop(['year_month','text','clean_doc'], axis=1, inplace=True)\n",
    "test = pd.read_csv(\"test_detoken.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_set = pd.concat([train.drop(\"smishing\",axis=1),test], sort=False)\n",
    "na_list = lda_set[lda_set['detoken'].isna()]['id']\n",
    "lda_set['detoken'].fillna(\" \", inplace=True)\n",
    "lda_set['detoken'] = lda_set['detoken'].str.replace(\"은행\", \" \")\n",
    "lda_set['detoken'] = lda_set['detoken'].str.replace(\"고객\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(297571, 297571, 297528)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lda_set[~lda_set.isin(na_list)]), len(lda_set), len(lda_set[~lda_set['id'].isin(na_list)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['성산', '팀장', '행복', '주말']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger = Mecab()\n",
    "\n",
    "result = []\n",
    "for i in lda_set['detoken']:\n",
    "    result.append(tagger.nouns(i))\n",
    "result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_set['detoken'] = result\n",
    "lda_set['detoken'].fillna(\" \", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions for stopwords, bigrams, trigrams and lemmatization\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    " \n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    " \n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    " \n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent))\n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):   \n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=num_topics, id2word=id2word)\n",
    "        model_list.append(model)\n",
    "        print(\"{0} topics model completed\".format(num_topics))\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "        print(coherencemodel.get_coherence())\n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['성산', '팀장', '행복', '주말']]\n"
     ]
    }
   ],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))\n",
    "\n",
    "data_words = list(sent_to_words(lda_set[~lda_set['id'].isin(na_list)]['detoken']))\n",
    "\n",
    "print(data_words[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['성산', '팀장', '행복', '주말']\n"
     ]
    }
   ],
   "source": [
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)\n",
    " \n",
    "# Faster way to get a sentence clubbed as a trigram/bigram\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    " \n",
    "# See trigram example\n",
    "print(trigram_mod[bigram_mod[data_words[0]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['성산', '팀장', '행복', '주말']]\n"
     ]
    }
   ],
   "source": [
    "# # Remove Stop Words\n",
    "# data_words_nostops = remove_stopwords(data_words)\n",
    " \n",
    "# # Form Bigrams\n",
    "# data_words_bigrams = make_bigrams(data_words_nostops)\n",
    " \n",
    "# # Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "# # python3 -m spacy download en\n",
    "# nlp = spacy.load('en', disable=['parser', 'ner'])\n",
    " \n",
    "# # Do lemmatization keeping only noun, adj, vb, adv\n",
    "# data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "data_lemmatized = data_words\n",
    "print(data_lemmatized[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 1), (3, 1)]]\n"
     ]
    }
   ],
   "source": [
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_lemmatized)\n",
    " \n",
    "# Create Corpus\n",
    "texts = data_lemmatized\n",
    " \n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    " \n",
    "# View\n",
    "print(corpus[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ.update({'MALLET_HOME':r'C:/mallet-2.0.8/'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download File: http://mallet.cs.umass.edu/dist/mallet-2.0.8.zip\n",
    "mallet_path = 'C:/mallet-2.0.8/bin/mallet' # update this path\n",
    "ldamallet = gensim.models.wrappers.LdaMallet(mallet_path, \n",
    "                                             corpus=corpus, \n",
    "                                             num_topics=2, \n",
    "                                             id2word=id2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.wrappers.ldamallet.malletmodel2ldamodel(ldamallet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\models\\ldamodel.py:1108: RuntimeWarning: invalid value encountered in multiply\n",
      "  score += np.sum((self.eta - _lambda) * Elogbeta)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\models\\ldamodel.py:1109: RuntimeWarning: invalid value encountered in subtract\n",
      "  score += np.sum(gammaln(_lambda) - gammaln(self.eta))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Perplexity:  nan\n",
      "\n",
      "Coherence Score:  0.6606596659164341\n"
     ]
    }
   ],
   "source": [
    "# Compute Perplexity\n",
    "print('\\nPerplexity: ', lda_model.log_perplexity(corpus)) # a measure of how good the model is. lower the better.\n",
    " \n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pyLDAvis\\_prepare.py:223: RuntimeWarning: divide by zero encountered in log\n",
      "  kernel = (topic_given_term * np.log((topic_given_term.T / topic_proportion).T))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pyLDAvis\\_prepare.py:240: RuntimeWarning: divide by zero encountered in log\n",
      "  log_lift = np.log(topic_term_dists / term_proportion)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pyLDAvis\\_prepare.py:241: RuntimeWarning: divide by zero encountered in log\n",
      "  log_ttd = np.log(topic_term_dists)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pyLDAvis\\_prepare.py:257: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  return pd.concat([default_term_info] + list(topic_dfs))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "3     -0.250740 -0.093264       1        1  31.601609\n",
       "0     -0.190966  0.092630       2        1  19.620373\n",
       "1     -0.119304 -0.040280       3        1  18.600403\n",
       "4      0.317809 -0.274128       4        1  15.455808\n",
       "2      0.243201  0.315043       5        1  14.721807, topic_info=    Category           Freq Term          Total  loglift  logprob\n",
       "9    Default  130861.000000   감사  130861.000000  30.0000  30.0000\n",
       "25   Default  102631.000000   지점  102631.000000  29.0000  29.0000\n",
       "3    Default   97343.000000   행복   97343.000000  28.0000  28.0000\n",
       "54   Default   65364.000000   거래   65364.000000  27.0000  27.0000\n",
       "8    Default   57237.000000   하루   57237.000000  26.0000  26.0000\n",
       "..       ...            ...  ...            ...      ...      ...\n",
       "3     Topic5   31260.052905   행복   97343.803065   0.7799  -3.5387\n",
       "109   Topic5   18881.882577   전화   52703.660083   0.8894  -4.0429\n",
       "14    Topic5   18912.536366   안녕   56130.092911   0.8280  -4.0412\n",
       "16    Topic5   12313.456773   올림   29872.260360   1.0296  -4.4704\n",
       "340   Topic5    8183.710189   언제   14226.298565   1.3629  -4.8789\n",
       "\n",
       "[425 rows x 6 columns], token_table=       Topic      Freq  Term\n",
       "term                        \n",
       "11541      2  0.877770    가권\n",
       "52         1  0.687558    가능\n",
       "52         2  0.277380    가능\n",
       "52         3  0.035065    가능\n",
       "21291      5  1.174406  가브리엘\n",
       "...      ...       ...   ...\n",
       "133        3  0.651550    확인\n",
       "658        3  0.999939    환율\n",
       "659        3  1.000049    환전\n",
       "7901       3  1.002716    회한\n",
       "10268      5  1.174406    희승\n",
       "\n",
       "[488 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[4, 1, 2, 5, 3])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model = gensim.models.wrappers.ldamallet.malletmodel2ldamodel(model_list[1])\n",
    "vis = pyLDAvis.gensim.prepare(lda_model, corpus, id2word)\n",
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  [('주말', 0.04153613272474304),\n",
      "   ('행복', 0.039115251012509566),\n",
      "   ('건강', 0.022678045198055236),\n",
      "   ('팀장', 0.022186122034129396),\n",
      "   ('마음', 0.021131779630817474),\n",
      "   ('사랑', 0.01430605522554096),\n",
      "   ('가을', 0.013468623823645158),\n",
      "   ('시작', 0.012735774511717842),\n",
      "   ('사람', 0.011856510273834645),\n",
      "   ('이번', 0.010820760242072678)]),\n",
      " (1,\n",
      "  [('금리', 0.037383329012185634),\n",
      "   ('가능', 0.03712683803103819),\n",
      "   ('상품', 0.03590966332086373),\n",
      "   ('상담', 0.03360170747064706),\n",
      "   ('등급', 0.031078002888995888),\n",
      "   ('대출', 0.02830151116708026),\n",
      "   ('신용', 0.024999074039779252),\n",
      "   ('한도', 0.024556002074150894),\n",
      "   ('통합', 0.01652514907959554),\n",
      "   ('진행', 0.01584179043668284)]),\n",
      " (2,\n",
      "  [('감사', 0.0957177645490395),\n",
      "   ('지점', 0.07212239272230883),\n",
      "   ('하루', 0.052314825984327344),\n",
      "   ('거래', 0.04676347737161971),\n",
      "   ('행복', 0.04627784137914396),\n",
      "   ('동의', 0.03151808721679989),\n",
      "   ('만족', 0.029589551977449058),\n",
      "   ('오늘', 0.028760702086444764),\n",
      "   ('저희', 0.02799255669449994),\n",
      "   ('부탁', 0.024425778243351886)]),\n",
      " (3,\n",
      "  [('금융', 0.02660297804734141),\n",
      "   ('가입', 0.025030578562755534),\n",
      "   ('센터', 0.021407223228709815),\n",
      "   ('혜택', 0.020404038302343587),\n",
      "   ('연금', 0.019911363038505953),\n",
      "   ('종합', 0.018445969946065805),\n",
      "   ('무료', 0.017581744709499938),\n",
      "   ('우대', 0.01668185067555216),\n",
      "   ('경우', 0.016245651007569216),\n",
      "   ('리브', 0.01578641524127712)]),\n",
      " (4,\n",
      "  [('대출', 0.0371140384308437),\n",
      "   ('이용', 0.03598860560338509),\n",
      "   ('전화', 0.019480900215965838),\n",
      "   ('지점', 0.018495535728827693),\n",
      "   ('신청', 0.017548445730032933),\n",
      "   ('상품', 0.01701748899812048),\n",
      "   ('안녕', 0.016621714501633588),\n",
      "   ('가능', 0.01435293312876841),\n",
      "   ('감사', 0.014325245201030642),\n",
      "   ('기간', 0.013586629011084943)])]\n",
      "\n",
      "Coherence Score:  0.609764863983559\n"
     ]
    }
   ],
   "source": [
    "# Show Topics\n",
    "pprint(ldamallet.show_topics(formatted=False))\n",
    " \n",
    "# Compute Coherence Score\n",
    "coherence_model_ldamallet = CoherenceModel(model=ldamallet, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "coherence_ldamallet = coherence_model_ldamallet.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_ldamallet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.042*\"주말\" + 0.039*\"행복\" + 0.023*\"건강\" + 0.022*\"팀장\" + 0.021*\"마음\" + 0.014*\"사랑\" '\n",
      "  '+ 0.013*\"가을\" + 0.013*\"시작\" + 0.012*\"사람\" + 0.011*\"이번\"'),\n",
      " (1,\n",
      "  '0.037*\"금리\" + 0.037*\"가능\" + 0.036*\"상품\" + 0.034*\"상담\" + 0.031*\"등급\" + 0.028*\"대출\" '\n",
      "  '+ 0.025*\"신용\" + 0.025*\"한도\" + 0.017*\"통합\" + 0.016*\"진행\"'),\n",
      " (2,\n",
      "  '0.096*\"감사\" + 0.072*\"지점\" + 0.052*\"하루\" + 0.047*\"거래\" + 0.046*\"행복\" + 0.032*\"동의\" '\n",
      "  '+ 0.030*\"만족\" + 0.029*\"오늘\" + 0.028*\"저희\" + 0.024*\"부탁\"'),\n",
      " (3,\n",
      "  '0.027*\"금융\" + 0.025*\"가입\" + 0.021*\"센터\" + 0.020*\"혜택\" + 0.020*\"연금\" + 0.018*\"종합\" '\n",
      "  '+ 0.018*\"무료\" + 0.017*\"우대\" + 0.016*\"경우\" + 0.016*\"리브\"'),\n",
      " (4,\n",
      "  '0.037*\"대출\" + 0.036*\"이용\" + 0.019*\"전화\" + 0.018*\"지점\" + 0.018*\"신청\" + 0.017*\"상품\" '\n",
      "  '+ 0.017*\"안녕\" + 0.014*\"가능\" + 0.014*\"감사\" + 0.014*\"기간\"')]\n"
     ]
    }
   ],
   "source": [
    "# Print the Keyword in the 10 topics\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 topics model completed\n",
      "0.6845119859827744\n",
      "20 topics model completed\n",
      "0.685753961238262\n",
      "23 topics model completed\n",
      "0.6728262354568272\n",
      "26 topics model completed\n",
      "0.6345309857390331\n",
      "29 topics model completed\n",
      "0.646266327529815\n"
     ]
    }
   ],
   "source": [
    "mallet_path = 'C:/mallet-2.0.8/bin/mallet' # update this path\n",
    "model_list, coherence_values = compute_coherence_values(dictionary=id2word, \n",
    "                                                        corpus=corpus, texts=data_lemmatized, \n",
    "                                                        start=17, limit=33, step=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.167*\"감사\" + 0.115*\"하루\" + 0.100*\"시간\" + 0.079*\"올림\" + 0.075*\"거래\" + 0.051*\"행복\" '\n",
      "  '+ 0.046*\"오늘\" + 0.042*\"내점\" + 0.035*\"저녁\" + 0.034*\"진심\"'),\n",
      " (1,\n",
      "  '0.037*\"금리\" + 0.033*\"상담\" + 0.030*\"가능\" + 0.027*\"등급\" + 0.026*\"진행\" + 0.024*\"추가\" '\n",
      "  '+ 0.022*\"상품\" + 0.022*\"이상\" + 0.020*\"통합\" + 0.019*\"부채\"'),\n",
      " (2,\n",
      "  '0.100*\"대출\" + 0.026*\"금리\" + 0.017*\"신용\" + 0.014*\"방문\" + 0.014*\"서류\" + 0.012*\"자금\" '\n",
      "  '+ 0.012*\"사업자\" + 0.011*\"안내\" + 0.011*\"증명\" + 0.010*\"지점\"'),\n",
      " (3,\n",
      "  '0.091*\"동의\" + 0.085*\"만족\" + 0.082*\"부탁\" + 0.068*\"업무\" + 0.059*\"전화\" + 0.053*\"처리\" '\n",
      "  '+ 0.042*\"계장\" + 0.038*\"조사\" + 0.036*\"추천\" + 0.027*\"설문\"'),\n",
      " (4,\n",
      "  '0.038*\"마음\" + 0.037*\"가을\" + 0.036*\"사람\" + 0.026*\"조심\" + 0.023*\"주말\" + 0.022*\"사랑\" '\n",
      "  '+ 0.021*\"가족\" + 0.020*\"감기\" + 0.019*\"바람\" + 0.018*\"계절\"'),\n",
      " (5,\n",
      "  '0.116*\"금융\" + 0.073*\"센터\" + 0.050*\"종합\" + 0.038*\"안녕\" + 0.037*\"연락\" + 0.035*\"전담\" '\n",
      "  '+ 0.029*\"사항\" + 0.021*\"예금\" + 0.021*\"확인\" + 0.017*\"언제\"'),\n",
      " (6,\n",
      "  '0.053*\"연금\" + 0.050*\"혜택\" + 0.045*\"가입\" + 0.035*\"경우\" + 0.032*\"공제\" + 0.029*\"납입\" '\n",
      "  '+ 0.028*\"세액\" + 0.027*\"금액\" + 0.027*\"퇴직\" + 0.025*\"관련\"'),\n",
      " (7,\n",
      "  '0.093*\"건강\" + 0.065*\"팀장\" + 0.062*\"행복\" + 0.037*\"날씨\" + 0.035*\"인사\" + 0.030*\"새해\" '\n",
      "  '+ 0.028*\"마음\" + 0.027*\"사랑\" + 0.025*\"이번\" + 0.024*\"시작\"'),\n",
      " (8,\n",
      "  '0.038*\"우대\" + 0.037*\"리브\" + 0.033*\"무료\" + 0.024*\"계좌\" + 0.023*\"서비스\" + '\n",
      "  '0.022*\"스타\" + 0.020*\"포인트\" + 0.020*\"수신\" + 0.018*\"거부\" + 0.017*\"광고\"'),\n",
      " (9,\n",
      "  '0.048*\"대출\" + 0.042*\"등급\" + 0.042*\"상품\" + 0.039*\"한도\" + 0.038*\"신용\" + 0.037*\"가능\" '\n",
      "  '+ 0.033*\"금리\" + 0.032*\"상담\" + 0.024*\"적용\" + 0.021*\"자격\"'),\n",
      " (10,\n",
      "  '0.062*\"상품\" + 0.055*\"가능\" + 0.052*\"이용\" + 0.049*\"신청\" + 0.026*\"전화\" + 0.025*\"광고\" '\n",
      "  '+ 0.024*\"수신\" + 0.021*\"접수\" + 0.020*\"정부\" + 0.020*\"상담\"'),\n",
      " (11,\n",
      "  '0.248*\"지점\" + 0.191*\"감사\" + 0.124*\"저희\" + 0.114*\"거래\" + 0.061*\"안녕\" + '\n",
      "  '0.024*\"서비스\" + 0.023*\"이용\" + 0.022*\"차장\" + 0.012*\"하루\" + 0.012*\"보답\"'),\n",
      " (12,\n",
      "  '0.023*\"지수\" + 0.023*\"증시\" + 0.021*\"만기\" + 0.019*\"상환\" + 0.018*\"시장\" + 0.016*\"하락\" '\n",
      "  '+ 0.015*\"경우\" + 0.013*\"지속\" + 0.013*\"상승\" + 0.012*\"투자\"'),\n",
      " (13,\n",
      "  '0.161*\"행복\" + 0.116*\"주말\" + 0.042*\"하루\" + 0.041*\"기분\" + 0.041*\"오늘\" + '\n",
      "  '0.032*\"마무리\" + 0.023*\"시작\" + 0.021*\"동지점\" + 0.018*\"금요일\" + 0.017*\"미소\"')]\n"
     ]
    }
   ],
   "source": [
    "# Select the model and print the topics\n",
    "optimal_model = model_list[2]\n",
    "model_topics = optimal_model.show_topics(formatted=False)\n",
    "pprint(optimal_model.print_topics(num_words=10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
